{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sB8ZW8Ow4bXQ",
        "outputId": "82a27040-f9c6-4905-e90a-7dc6a95579a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# SENTETIKLE FINE-TUNE EDILMIS MODEL -> SADECE REAL TEST\n",
        "# ============================================================\n",
        "\n",
        "import os, json, random, numpy as np, cv2\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms as T, models\n",
        "from tqdm import tqdm\n",
        "\n",
        "# ---------------- Paths ----------------\n",
        "REAL_ROOT = \"/content/drive/MyDrive/dataset_split/real_gaze_vectors_videos_and_texts_split\"\n",
        "\n",
        "# BURAYI: sentetik fine-tune sonucunda kaydettiğin checkpoint'e göre değiştir\n",
        "CKPT_PATH = \"/content/drive/MyDrive/dataset_split/best_gaze_synthetic_from_real_lastpt_resnet50.pt\"\n",
        "\n",
        "# ---------------- Env ----------------\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Device:\", device)\n",
        "torch.manual_seed(42)\n",
        "if device == \"cuda\":\n",
        "    torch.cuda.manual_seed_all(42)\n",
        "np.random.seed(42)\n",
        "random.seed(42)\n",
        "\n",
        "# ============================================================\n",
        "# Yardımcı: Angular Error\n",
        "# ============================================================\n",
        "\n",
        "def angular_error_deg(pred, gt):\n",
        "    pred = F.normalize(pred, dim=1)\n",
        "    gt   = F.normalize(gt,   dim=1)\n",
        "    cos_sim = torch.clamp(torch.sum(pred * gt, dim=1), -1.0, 1.0)\n",
        "    return torch.rad2deg(torch.acos(cos_sim))\n",
        "\n",
        "# ============================================================\n",
        "# REAL TEyeD Dataset\n",
        "# ============================================================\n",
        "\n",
        "class TEyeDRealDataset(Dataset):\n",
        "    \"\"\"\n",
        "    REAL TEyeD:\n",
        "      REAL_ROOT/test/*.mp4\n",
        "      REAL_ROOT/test/*.mp4gaze_vec.txt\n",
        "\n",
        "    TXT satır formatı:\n",
        "      FRAME;X;Y;Z;\n",
        "      1;-0.0218;-0.0039;0.9997;\n",
        "      ...\n",
        "    \"\"\"\n",
        "    def __init__(self, root_dir, split=\"test\", transform=None):\n",
        "        self.root_dir = os.path.join(root_dir, split)\n",
        "        self.transform = transform\n",
        "        self.samples = []  # (video_path, frame_idx, (gx,gy,gz))\n",
        "\n",
        "        if not os.path.exists(self.root_dir):\n",
        "            print(f\"⚠️ REAL path not found: {self.root_dir}\")\n",
        "            return\n",
        "\n",
        "        video_files = sorted([f for f in os.listdir(self.root_dir) if f.lower().endswith(\".mp4\")])\n",
        "        print(f\"[REAL-{split}] found {len(video_files)} videos.\")\n",
        "\n",
        "        for vname in tqdm(video_files, desc=f\"Indexing REAL-{split}\"):\n",
        "            vpath = os.path.join(self.root_dir, vname)\n",
        "            txt_path = vpath + \"gaze_vec.txt\"\n",
        "            if not os.path.exists(txt_path):\n",
        "                print(f\"⚠️ Gaze file missing for {vname}\")\n",
        "                continue\n",
        "\n",
        "            frame_ids, gazes = self._load_gaze_file(txt_path)\n",
        "\n",
        "            cap = cv2.VideoCapture(vpath)\n",
        "            if not cap.isOpened():\n",
        "                print(f\"⚠️ Could not open video: {vpath}\")\n",
        "                continue\n",
        "            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "            cap.release()\n",
        "\n",
        "            L = min(total_frames, len(frame_ids))\n",
        "            for i in range(L):\n",
        "                self.samples.append((vpath, int(frame_ids[i]), gazes[i]))\n",
        "\n",
        "        print(f\"REAL-{split}: {len(self.samples)} samples\")\n",
        "\n",
        "    def _load_gaze_file(self, txt_path):\n",
        "        frame_ids = []\n",
        "        gazes = []\n",
        "        with open(txt_path, \"r\") as f:\n",
        "            for line in f:\n",
        "                line = line.strip()\n",
        "                if not line:\n",
        "                    continue\n",
        "                if line.upper().startswith(\"FRAME\"):\n",
        "                    continue\n",
        "                parts = line.split(\";\")\n",
        "                if len(parts) < 4:\n",
        "                    continue\n",
        "                try:\n",
        "                    fid = int(float(parts[0]))\n",
        "                    gx = float(parts[1]); gy = float(parts[2]); gz = float(parts[3])\n",
        "                except ValueError:\n",
        "                    continue\n",
        "                frame_ids.append(max(0, fid - 1))  # 1-based -> 0-based\n",
        "                gazes.append([gx, gy, gz])\n",
        "        frame_ids = np.array(frame_ids, dtype=np.int64)\n",
        "        gazes = np.array(gazes, dtype=np.float32)\n",
        "        return frame_ids, gazes\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        vpath, fidx, gaze = self.samples[idx]\n",
        "        cap = cv2.VideoCapture(vpath)\n",
        "        if not cap.isOpened():\n",
        "            raise RuntimeError(f\"Could not open video {vpath}\")\n",
        "        cap.set(cv2.CAP_PROP_POS_FRAMES, fidx)\n",
        "        ok, frame = cap.read()\n",
        "        cap.release()\n",
        "        if not ok:\n",
        "            raise RuntimeError(f\"Could not read frame {fidx} from {vpath}\")\n",
        "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        if self.transform is not None:\n",
        "            frame = self.transform(frame)\n",
        "\n",
        "        tgt = torch.tensor(gaze, dtype=torch.float32)\n",
        "        return frame, tgt\n",
        "\n",
        "# ============================================================\n",
        "# Transform, DataLoader\n",
        "# ============================================================\n",
        "\n",
        "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
        "IMAGENET_STD  = [0.229, 0.224, 0.225]\n",
        "\n",
        "real_tf_eval = T.Compose([\n",
        "    T.ToPILImage(),\n",
        "    T.Resize((224, 224)),\n",
        "    # İstersen burada T.Grayscale(num_output_channels=3) ekleyebilirsin\n",
        "    T.ToTensor(),\n",
        "    T.Normalize(IMAGENET_MEAN, IMAGENET_STD),\n",
        "])\n",
        "\n",
        "BATCH_SIZE = 8\n",
        "NUM_WORKERS = 4 if device == \"cuda\" else 2\n",
        "\n",
        "def make_loader(ds, shuffle=False):\n",
        "    return DataLoader(\n",
        "        ds,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=shuffle,\n",
        "        num_workers=NUM_WORKERS,\n",
        "        pin_memory=(device==\"cuda\"),\n",
        "        persistent_workers=(device==\"cuda\" and NUM_WORKERS>0 and len(ds)>0),\n",
        "        prefetch_factor=4 if device==\"cuda\" else 2,\n",
        "    )\n",
        "\n",
        "real_test_dataset = TEyeDRealDataset(REAL_ROOT, \"test\", real_tf_eval)\n",
        "real_test_loader  = make_loader(real_test_dataset, shuffle=False)\n",
        "\n",
        "print(f\"REAL Test samples: {len(real_test_dataset)}\")\n",
        "\n",
        "# ============================================================\n",
        "# Model: ResNet50 -> 3D gaze, sentetik-finetune checkpoint'ini yükle\n",
        "# ============================================================\n",
        "\n",
        "gaze_model = models.resnet50(weights=None)  # Ağırlıklar checkpoint'ten gelecek\n",
        "gaze_model.fc = nn.Linear(gaze_model.fc.in_features, 3)\n",
        "gaze_model = gaze_model.to(device)\n",
        "\n",
        "# Checkpoint yükle (state_dict veya 'state_dict' key'ine göre)\n",
        "ckpt = torch.load(CKPT_PATH, map_location=\"cpu\")\n",
        "state = ckpt.get(\"state_dict\", ckpt)  # hem plain state_dict hem de dict-wrapper için\n",
        "missing, unexpected = gaze_model.load_state_dict(state, strict=False)\n",
        "print(\"Checkpoint loaded from:\", CKPT_PATH)\n",
        "print(\"Missing keys:\", missing)\n",
        "print(\"Unexpected keys:\", unexpected)\n",
        "\n",
        "gaze_model.eval()\n",
        "\n",
        "# ============================================================\n",
        "# TEST: sentetik-finetuned modelin REAL test üzerindeki performansı\n",
        "# ============================================================\n",
        "\n",
        "test_angles_real = []\n",
        "with torch.no_grad():\n",
        "    for xr, tr in tqdm(real_test_loader, desc=\"REAL Test\"):\n",
        "        xr, tr = xr.to(device), tr.to(device)\n",
        "        out = gaze_model(xr)\n",
        "        ang = angular_error_deg(out, tr)\n",
        "        test_angles_real.append(ang.mean().item())\n",
        "\n",
        "if len(test_angles_real) > 0:\n",
        "    mean_ang = float(np.mean(test_angles_real))\n",
        "    print(f\"✅ SYNTHETIC-FINETUNED MODEL on REAL TEST Angular Error: {mean_ang:.2f}°\")\n",
        "else:\n",
        "    print(\"⚠️ REAL TEST dataset boş; hiçbir batch işlenmedi.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Uhhy5lf4f6C",
        "outputId": "d8dba429-81ba-4405-a1cb-200289487b82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n",
            "[REAL-test] found 17 videos.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Indexing REAL-test: 100%|██████████| 17/17 [01:01<00:00,  3.59s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "REAL-test: 194572 samples\n",
            "REAL Test samples: 194572\n",
            "Checkpoint loaded from: /content/drive/MyDrive/dataset_split/best_gaze_synthetic_from_real_lastpt_resnet50.pt\n",
            "Missing keys: []\n",
            "Unexpected keys: []\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "REAL Test: 100%|██████████| 24322/24322 [27:48<00:00, 14.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ SYNTHETIC-FINETUNED MODEL on REAL TEST Angular Error: 12.33°\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8Lie37Jl4f3O"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}